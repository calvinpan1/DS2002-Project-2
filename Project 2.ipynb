{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a83a32-581e-4e42-a305-ae7f890fddd5",
   "metadata": {},
   "source": [
    "## DS 2002 Project 2\n",
    "Project completed according to the requirements sent out via email/Canvas Course Announcement on April 15 (and also drawing from the requirements of the project document here that don't conflict with the version sent out via email: https://github.com/JTupitza-UVA/DS-2002/blob/main/Projects/DS-2002-Data-Project-2-Capstone.pdf)\n",
    "\n",
    "### Project Info:\n",
    "**Author Name**: Calvin Pan  \n",
    "**Author Computing ID**: nqc8gh@virginia.edu  \n",
    "**Instructor Name**: Jon Tupitza  \n",
    "**Course**: DS 2002 Data Science Systems - Spring 2025 Section 001  \n",
    "**Due Date**: 5/09/2025  \n",
    "\n",
    "## Step 0: Setup\n",
    "### Step 0.1: Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db2c2ed5-a8ff-4751-95db-6a514189bb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pyspark\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print(findspark.find())\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pymongo\n",
    "import certifi\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window as W\n",
    "\n",
    "import pymongo\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65824406-5b9c-4624-b456-ef62542d53ac",
   "metadata": {},
   "source": [
    "### Step 0.2: Instantiate Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b0fa87c8-9565-4721-8637-a96c5754be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Specify MySQL Server Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "mysql_args = {\n",
    "    \"host_name\" : \"127.0.0.1\",\n",
    "    \"port\" : \"3306\",\n",
    "    \"db_name\" : \"adventureworks\",\n",
    "    \"conn_props\" : {\n",
    "        \"user\" : \"root\",\n",
    "        \"password\" : \"#Pelican1\",\n",
    "        \"driver\" : \"com.mysql.cj.jdbc.Driver\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify MongoDB Cluster Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "mongodb_args = {\n",
    "    \"cluster_location\" : \"atlas\", # \"local\"\n",
    "    \"user_name\" : \"calvinpan1\",\n",
    "    \"password\" : \"Pelican1\",\n",
    "    \"cluster_name\" : \"ds2002\",\n",
    "    \"cluster_subnet\" : \"hc2ph\",\n",
    "    \"db_name\" : \"lab6pyspark\",\n",
    "    \"collection\" : \"project2\",\n",
    "    \"null_column_threshold\" : 0.5\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify Directory Structure for Source Data\n",
    "# --------------------------------------------------------------------------------\n",
    "base_dir = os.path.join(os.getcwd(), 'project_data')\n",
    "data_dir = os.path.join(base_dir, 'adventureworks')\n",
    "batch_dir = os.path.join(data_dir, 'batch')\n",
    "stream_dir = os.path.join(data_dir, 'streaming')\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Create Directory Structure for Data Lakehouse Files\n",
    "# --------------------------------------------------------------------------------\n",
    "dest_database = \"adventureworks_dlh\"\n",
    "sql_warehouse_dir = os.path.abspath('spark-warehouse')\n",
    "dest_database_dir = f\"{dest_database}.db\"\n",
    "database_dir = os.path.join(sql_warehouse_dir, dest_database_dir)\n",
    "\n",
    "output_bronze = os.path.join(database_dir, 'bronze')\n",
    "output_silver = os.path.join(database_dir, 'silver')\n",
    "output_gold = os.path.join(database_dir, 'gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b9577-65e6-4498-bd8d-d81ea49dbc53",
   "metadata": {},
   "source": [
    "### Step 0.3. Define Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a27295d8-aab5-4f50-af05-84381e9bd2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(path: str):\n",
    "    file_sizes = []\n",
    "    modification_times = []\n",
    "\n",
    "    '''Fetch each item in the directory, and filter out any directories.'''\n",
    "    items = os.listdir(path)\n",
    "    files = sorted([item for item in items if os.path.isfile(os.path.join(path, item))])\n",
    "\n",
    "    '''Populate lists with the Size and Last Modification DateTime for each file in the directory.'''\n",
    "    for file in files:\n",
    "        file_sizes.append(os.path.getsize(os.path.join(path, file)))\n",
    "        modification_times.append(pd.to_datetime(os.path.getmtime(os.path.join(path, file)), unit='s'))\n",
    "\n",
    "    data = list(zip(files, file_sizes, modification_times))\n",
    "    column_names = ['name','size','modification_time']\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns=column_names)\n",
    "\n",
    "\n",
    "def wait_until_stream_is_ready(query, min_batches=1):\n",
    "    while len(query.recentProgress) < min_batches:\n",
    "        time.sleep(5)\n",
    "        \n",
    "    print(f\"The stream has processed {len(query.recentProgress)} batchs\")\n",
    "\n",
    "\n",
    "def remove_directory_tree(path: str):\n",
    "    '''If it exists, remove the entire contents of a directory structure at a given 'path' parameter's location.'''\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "            return f\"Directory '{path}' has been removed successfully.\"\n",
    "        else:\n",
    "            return f\"Directory '{path}' does not exist.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "        \n",
    "\n",
    "def drop_null_columns(df, threshold):\n",
    "    '''Drop Columns having a percentage of NULL values that exceeds the given 'threshold' parameter value.'''\n",
    "    columns_with_nulls = [col for col in df.columns if df.filter(df[col].isNull()).count() / df.count() > threshold] \n",
    "    df_dropped = df.drop(*columns_with_nulls) \n",
    "    \n",
    "    return df_dropped\n",
    "\n",
    "def get_sql_dataframe(sql_query, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['conn_props']['user']}:{args['conn_props']['password']}@{args['host_name']}/{args['db_name']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    dframe = pd.read_sql(text(sql_query), connection);\n",
    "    connection.close()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "def get_mysql_dataframe(spark_session, sql_query : str, **args):\n",
    "    '''Create a JDBC URL to the MySQL Database'''\n",
    "    jdbc_url = f\"jdbc:mysql://{args['host_name']}:{args['port']}/{args['db_name']}\"\n",
    "    \n",
    "    '''Invoke the spark.read.format(\"jdbc\") function to query the database, and fill a DataFrame.'''\n",
    "    dframe = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"driver\", args['conn_props']['driver']) \\\n",
    "    .option(\"user\", args['conn_props']['user']) \\\n",
    "    .option(\"password\", args['conn_props']['password']) \\\n",
    "    .option(\"query\", sql_query) \\\n",
    "    .load()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "\n",
    "def get_mongo_uri(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the 'cluster_location' parameter.\")\n",
    "        \n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        uri = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "        uri += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net/\"\n",
    "    else:\n",
    "        uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "    return uri\n",
    "\n",
    "\n",
    "def get_spark_conf_args(spark_jars : list, **args):\n",
    "    jars = \"\"\n",
    "    for jar in spark_jars:\n",
    "        jars += f\"{jar}, \"\n",
    "    \n",
    "    sparkConf_args = {\n",
    "        \"app_name\" : \"PySpark Northwind Data Lakehouse (Medallion Architecture)\",\n",
    "        \"worker_threads\" : f\"local[{int(os.cpu_count()/2)}]\",\n",
    "        \"shuffle_partitions\" : int(os.cpu_count()),\n",
    "        \"mongo_uri\" : get_mongo_uri(**args),\n",
    "        \"spark_jars\" : jars[0:-2],\n",
    "        \"database_dir\" : sql_warehouse_dir\n",
    "    }\n",
    "    \n",
    "    return sparkConf_args\n",
    "    \n",
    "\n",
    "def get_spark_conf(**args):\n",
    "    sparkConf = SparkConf().setAppName(args['app_name'])\\\n",
    "    .setMaster(args['worker_threads']) \\\n",
    "    .set('spark.driver.memory', '4g') \\\n",
    "    .set('spark.executor.memory', '2g') \\\n",
    "    .set('spark.jars', args['spark_jars']) \\\n",
    "    .set('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
    "    .set('spark.mongodb.input.uri', args['mongo_uri']) \\\n",
    "    .set('spark.mongodb.output.uri', args['mongo_uri']) \\\n",
    "    .set('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .set('spark.sql.debug.maxToStringFields', 35) \\\n",
    "    .set('spark.sql.shuffle.partitions', args['shuffle_partitions']) \\\n",
    "    .set('spark.sql.streaming.forceDeleteTempCheckpointLocation', 'true') \\\n",
    "    .set('spark.sql.streaming.schemaInference', 'true') \\\n",
    "    .set('spark.sql.warehouse.dir', args['database_dir']) \\\n",
    "    .set('spark.streaming.stopGracefullyOnShutdown', 'true')\n",
    "    \n",
    "    return sparkConf\n",
    "\n",
    "\n",
    "def get_mongo_client(**args):\n",
    "    '''Get MongoDB Client Connection'''\n",
    "    mongo_uri = get_mongo_uri(**args)\n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        client = pymongo.MongoClient(mongo_uri, tlsCAFile=certifi.where())\n",
    "\n",
    "    elif args['cluster_location'] == \"local\":\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"A MongoDB Client could not be created.\")\n",
    "\n",
    "    return client\n",
    "    \n",
    "    \n",
    "# TODO: Rewrite this to leverage PySpark?\n",
    "def set_mongo_collections(mongo_client, db_name : str, data_directory : str, json_files : list):\n",
    "    db = mongo_client[db_name]\n",
    "    \n",
    "    for file in json_files:\n",
    "        db.drop_collection(file)\n",
    "        json_file = os.path.join(data_directory, json_files[file])\n",
    "        with open(json_file, 'r') as openfile:\n",
    "            json_object = json.load(openfile)\n",
    "            file = db[file]\n",
    "            result = file.insert_many(json_object)\n",
    "        \n",
    "    mongo_client.close()\n",
    "    \n",
    "\n",
    "def get_mongodb_dataframe(spark_session, **args):\n",
    "    '''Query MongoDB, and create a DataFrame'''\n",
    "    uri = f\"mongodb+srv://{args['user_name']}:{args['password']}@{args['cluster_subnet']}.{args['cluster_name']}.mongodb.net/{args['db_name']}?retryWrites=true&w=majority\"\n",
    "    \n",
    "    dframe = spark_session.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "        .option(\"database\", args['db_name']) \\\n",
    "        .option(\"collection\", args['collection']).load()\n",
    "\n",
    "    '''Drop the '_id' index column to clean up the response.'''\n",
    "    dframe = dframe.drop('_id')\n",
    "    \n",
    "    '''Call the drop_null_columns() function passing in the dataframe.'''\n",
    "    dframe = drop_null_columns(dframe, args['null_column_threshold'])\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "def get_mongo_dataframe(mongo_client, db_name, collection, query):\n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = mongo_client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    mongo_client.close()\n",
    "    \n",
    "    return dframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770b48f-0cee-42b4-915f-a9a45b7e4837",
   "metadata": {},
   "source": [
    "### Step 0.4: Initialize Data Lakehouse Directory Structure\n",
    "Remove the Data Lakehouse Database Directory Structure to Ensure Idempotency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7cb73f24-e46c-43d5-88ff-81b50aa941d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Directory '/Users/calvin/Documents/Calvin/UVA/2024-25/DS 2002 - Data Science Systems/Projects/Project 2/spark-warehouse/adventureworks_dlh.db' has been removed successfully.\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_directory_tree(database_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac9e17-65cc-4927-b9be-201fda8dcc70",
   "metadata": {},
   "source": [
    "### Step 0.5: Create a New Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d428b6f9-b0f8-42d7-b54b-7fc9d2b96ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://mac:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Northwind Data Lakehouse (Medallion Architecture)</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x154521fd0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_threads = f\"local[{int(os.cpu_count()/2)}]\"\n",
    "\n",
    "jars = []\n",
    "mysql_spark_jar = os.path.join(os.getcwd(), \"mysql-connector-j-9.1.0\", \"mysql-connector-j-9.1.0.jar\")\n",
    "mssql_spark_jar = os.path.join(os.getcwd(), \"sqljdbc_12.8\", \"enu\", \"jars\", \"mssql-jdbc-12.8.1.jre11.jar\")\n",
    "\n",
    "jars.append(mysql_spark_jar)\n",
    "#jars.append(mssql_spark_jar)\n",
    "\n",
    "sparkConf_args = get_spark_conf_args(jars, **mongodb_args)\n",
    "\n",
    "sparkConf = get_spark_conf(**sparkConf_args)\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e1602-5f54-467a-bc70-a4e7a059b0a8",
   "metadata": {},
   "source": [
    "### Step 0.6\" Create a New Metadata Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35d529ba-dfc9-4d08-b5ad-d23b40135a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DROP DATABASE IF EXISTS {dest_database} CASCADE;\")\n",
    "\n",
    "sql_create_db = f\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS {dest_database}\n",
    "    COMMENT 'DS-2002 PROJECT 2 Database'\n",
    "    WITH DBPROPERTIES (contains_pii = true, purpose = 'DS-2002 Lab 6.0');\n",
    "\"\"\"\n",
    "spark.sql(sql_create_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101cd47-c866-4336-90d4-2bdfa13e4bf4",
   "metadata": {},
   "source": [
    "## Step 1: Exporting adventureworks to everything\n",
    "### Step 1.1: Downloading adventureworks and exporting it into MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559e4cb-ac6e-47cb-bdd4-f651ed82b26b",
   "metadata": {},
   "source": [
    "Done via running this script in my local SQL instance: https://github.com/JTupitza-UVA/DS-2002/blob/main/Projects/Scripts/AdventureWorks_MySQL.sql "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d46a1-2ecd-4fc8-b069-66d910626ee6",
   "metadata": {},
   "source": [
    "### Step 1.2 Exporting dim_date into the adventureworks schema in MySQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de864c-43b9-4aaf-a3c2-b80d4882380d",
   "metadata": {},
   "source": [
    "Done via running in my local SQL instance a slightly edited version of the Lab 2b code for dim_date obtained here (only change was to replace USE northwind_dw with USE adventureworks): https://github.com/JTupitza-UVA/DS-2002/blob/main/01-SQL/Labs/Lab_02c_Create_Populate_Dim_Date.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7e6fd-bac5-4f1f-81b0-4d6b3cce14cc",
   "metadata": {},
   "source": [
    "### Step 1.3 Exporting PurchaseOrderHeader from the adventureworks table into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1426bc56-a9b8-4f71-a72f-253e053f5ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>Status</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>ShipMethodID</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>SubTotal</th>\n",
       "      <th>TaxAmt</th>\n",
       "      <th>Freight</th>\n",
       "      <th>TotalDue</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>2001-05-26</td>\n",
       "      <td>201.0400</td>\n",
       "      <td>16.0832</td>\n",
       "      <td>5.0260</td>\n",
       "      <td>222.1492</td>\n",
       "      <td>2001-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-05-17</td>\n",
       "      <td>2001-05-26</td>\n",
       "      <td>272.1015</td>\n",
       "      <td>21.7681</td>\n",
       "      <td>6.8025</td>\n",
       "      <td>300.6721</td>\n",
       "      <td>2001-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderID  RevisionNumber  Status  EmployeeID  VendorID  \\\n",
       "0                1               0       4         244        83   \n",
       "1                2               0       1         231        32   \n",
       "\n",
       "   ShipMethodID  OrderDate   ShipDate  SubTotal   TaxAmt  Freight  TotalDue  \\\n",
       "0             3 2001-05-17 2001-05-26  201.0400  16.0832   5.0260  222.1492   \n",
       "1             5 2001-05-17 2001-05-26  272.1015  21.7681   6.8025  300.6721   \n",
       "\n",
       "  ModifiedDate  \n",
       "0   2001-05-26  \n",
       "1   2001-05-26  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the SQL purchaseorderheader data to a dataframe:\n",
    "sql_get_adventureworks_poh = 'SELECT * FROM adventureworks.purchaseorderheader'\n",
    "df_dim_purchaseorderheader = get_sql_dataframe(sql_get_adventureworks_poh, **mysql_args)\n",
    "df_dim_purchaseorderheader.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bb827fa3-ff41-4d83-8720-f42a566216d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to a JSON formatted dict:\n",
    "dict_dim_purchaseorderheader = df_dim_purchaseorderheader.to_dict(orient='records')\n",
    "\n",
    "# To avoid date type error, convert DataFrame to JSON with ISO dates and load back into a dictionary\n",
    "dict_dim_purchaseorderheader = json.loads(\n",
    "    df_dim_purchaseorderheader.to_json(date_format='iso', orient='records')\n",
    ")\n",
    "\n",
    "# Write the dict to a JSON file:\n",
    "with open(os.path.join(batch_dir, 'purchaseorderheader.json'), \"w\") as o:\n",
    "    json.dump(dict_dim_purchaseorderheader, o, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a70e2b3d-035c-4733-8bc1-85b44a2c0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file to MongoDB \n",
    "client = get_mongo_client(**mongodb_args)\n",
    "json_files = {'purchaseorderheader': 'purchaseorderheader.json'}\n",
    "set_mongo_collections(client, mongodb_args[\"db_name\"], batch_dir, json_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2863c6fa-0682-4a02-b08b-fd82c135cf9a",
   "metadata": {},
   "source": [
    "### Step 1.4 Exporting products from the SQL adventureworks table into a CSV through a PySQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "776dd996-b490-4980-908e-8fe4e8b12296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>MakeFlag</th>\n",
       "      <th>FinishedGoodsFlag</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>ProductLine</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductSubcategoryID</th>\n",
       "      <th>ProductModelID</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>b'\\xb7\\x15Bi\\xf7\\x08\\rL\\xac\\xb1\\xd74\\xbaD\\xc0\\...</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>BA-8327</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>b' &lt;\\xaeX:OIG\\xa7\\xd4\\xd5h\\x80l\\xc57'</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID             Name ProductNumber MakeFlag FinishedGoodsFlag Color  \\\n",
       "0          1  Adjustable Race       AR-5381  b'\\x00'           b'\\x00'  None   \n",
       "1          2     Bearing Ball       BA-8327  b'\\x00'           b'\\x00'  None   \n",
       "\n",
       "   SafetyStockLevel  ReorderPoint  StandardCost  ListPrice  ... ProductLine  \\\n",
       "0              1000           750           0.0        0.0  ...        None   \n",
       "1              1000           750           0.0        0.0  ...        None   \n",
       "\n",
       "  Class Style  ProductSubcategoryID  ProductModelID SellStartDate SellEndDate  \\\n",
       "0  None  None                   NaN             NaN    1998-06-01         NaT   \n",
       "1  None  None                   NaN             NaN    1998-06-01         NaT   \n",
       "\n",
       "  DiscontinuedDate                                            rowguid  \\\n",
       "0             None  b'\\xb7\\x15Bi\\xf7\\x08\\rL\\xac\\xb1\\xd74\\xbaD\\xc0\\...   \n",
       "1             None              b' <\\xaeX:OIG\\xa7\\xd4\\xd5h\\x80l\\xc57'   \n",
       "\n",
       "         ModifiedDate  \n",
       "0 2004-03-11 10:01:36  \n",
       "1 2004-03-11 10:01:36  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the SQL products data to a dataframe:\n",
    "sql_get_adventureworks_products = 'SELECT * FROM adventureworks.product'\n",
    "df_dim_products = get_sql_dataframe(sql_get_adventureworks_products, **mysql_args)\n",
    "df_dim_products.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6fc4631b-1a6f-4d82-95b7-bfacb24f5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to a CSV:\n",
    "dest_file = (os.path.join(batch_dir, 'products.csv'))\n",
    "csv_dim_products = df_dim_products.to_csv(dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5dfb5-53bd-4e2f-88c4-6509003cc338",
   "metadata": {},
   "source": [
    "### Step 1.5 Extracting purchaseorderdetail from the SQL adventureworks table into 3 separate jsons to be used for batch data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc0432-d5ec-4c0e-9ad6-4ed22c5bbf3e",
   "metadata": {},
   "source": [
    "#### Step 1.5.1 Export from SQL adventureworks table into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19e28d0b-9196-4f05-8b99-81b19034698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>PurchaseOrderDetailID</th>\n",
       "      <th>DueDate</th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>LineTotal</th>\n",
       "      <th>ReceivedQty</th>\n",
       "      <th>RejectedQty</th>\n",
       "      <th>StockedQty</th>\n",
       "      <th>...</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>CurrentFlag</th>\n",
       "      <th>EmpModifiedDate</th>\n",
       "      <th>Employee_Key</th>\n",
       "      <th>PurchaseOrderHistory_Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50.26</td>\n",
       "      <td>201.04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>2000-03-03</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>\u0001</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>3</td>\n",
       "      <td>359</td>\n",
       "      <td>45.12</td>\n",
       "      <td>135.36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>2000-02-05</td>\n",
       "      <td>\u0000</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>\u0001</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderID  PurchaseOrderDetailID    DueDate  OrderQty  ProductID  \\\n",
       "0                1                      1 2001-05-31         4          1   \n",
       "1                2                      2 2001-05-31         3        359   \n",
       "\n",
       "   UnitPrice  LineTotal  ReceivedQty  RejectedQty  StockedQty  ...  \\\n",
       "0      50.26     201.04          3.0          0.0         3.0  ...   \n",
       "1      45.12     135.36          3.0          0.0         3.0  ...   \n",
       "\n",
       "  MaritalStatus  Gender   HireDate SalariedFlag VacationHours  SickLeaveHours  \\\n",
       "0             S       F 2000-03-03            \u0000            53              46   \n",
       "1             M       M 2000-02-05            \u0000            57              48   \n",
       "\n",
       "   CurrentFlag  EmpModifiedDate  Employee_Key PurchaseOrderHistory_Key  \n",
       "0            \u0001       2004-07-31           244                        1  \n",
       "1            \u0001       2004-07-31           231                        2  \n",
       "\n",
       "[2 rows x 62 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export from SQL adventureworks table into a dataframe\n",
    "sql_get_pod = 'SELECT * FROM adventureworks.purchaseorderdetail'\n",
    "df_pod = get_sql_dataframe(sql_get_pod, **mysql_args)\n",
    "df_pod.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0098e-02b0-44ac-b2de-1bfb869f23bf",
   "metadata": {},
   "source": [
    "#### Step 1.5.2 Split this dataframe into 3 .jsons and save them each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "deaf78a9-578e-4e1c-9d10-44cba9fcf27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2929 records to /Users/calvin/Documents/Calvin/UVA/2024-25/DS 2002 - Data Science Systems/Projects/Project 2/project_data/adventureworks/streaming/purchaseorderdetail_part1.json\n",
      "Saved 2929 records to /Users/calvin/Documents/Calvin/UVA/2024-25/DS 2002 - Data Science Systems/Projects/Project 2/project_data/adventureworks/streaming/purchaseorderdetail_part2.json\n",
      "Saved 2930 records to /Users/calvin/Documents/Calvin/UVA/2024-25/DS 2002 - Data Science Systems/Projects/Project 2/project_data/adventureworks/streaming/purchaseorderdetail_part3.json\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of records\n",
    "total_records = len(df_pod)\n",
    "\n",
    "# Calculate the number of records per split\n",
    "records_per_split = total_records // 3\n",
    "\n",
    "# Determine the split points\n",
    "split_points = [records_per_split, 2 * records_per_split]\n",
    "\n",
    "# Split the DataFrame into three parts\n",
    "df_part1 = df_pod.iloc[:split_points[0]]\n",
    "df_part2 = df_pod.iloc[split_points[0]:split_points[1]]\n",
    "df_part3 = df_pod.iloc[split_points[1]:]\n",
    "\n",
    "# Define the base filename\n",
    "base_filename = 'purchaseorderdetail_part'\n",
    "\n",
    "# Save each part as a JSON file\n",
    "dataframes_to_save = [df_part1, df_part2, df_part3]\n",
    "\n",
    "for i, df_part in enumerate(dataframes_to_save):\n",
    "    # Convert DataFrame to JSON formatted string with ISO dates\n",
    "    json_string = df_part.to_json(date_format='iso', orient='records')\n",
    "\n",
    "    # Load the JSON string into a dictionary\n",
    "    dict_part = json.loads(json_string)\n",
    "\n",
    "    # Define the output filename\n",
    "    output_filename = f'{base_filename}{i + 1}.json'\n",
    "    output_filepath = os.path.join(stream_dir, output_filename)\n",
    "\n",
    "    # Write the dictionary to a JSON file\n",
    "    with open(output_filepath, \"w\") as o:\n",
    "        json.dump(dict_part, o, indent=4)\n",
    "\n",
    "    print(f\"Saved {len(df_part)} records to {output_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5a223-8da3-4e49-a1f6-d8921c6a8244",
   "metadata": {},
   "source": [
    "## Step 2: Extracting all the BATCH data from all necessary sources (Cold Path)\n",
    "### Step 2.1: Extracting employees from the MySQL version of adventureworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "42888ecb-fc62-43b6-8482-c1e42936aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_get_employees = 'SELECT * FROM adventureworks.employee'\n",
    "df_dim_employees = get_mysql_dataframe(spark, sql_get_employees, **mysql_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e81dd565-2cb0-4f55-983c-1efd626e1e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeKey</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>ContactID</th>\n",
       "      <th>LoginID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>Title</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>CurrentFlag</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14417807</td>\n",
       "      <td>1209</td>\n",
       "      <td>adventure-works\\guy1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>1972-05-15</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>253022876</td>\n",
       "      <td>1030</td>\n",
       "      <td>adventure-works\\kevin0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>1977-06-03</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-02-26</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeKey  EmployeeID NationalIDNumber  ContactID  \\\n",
       "0            1           1         14417807       1209   \n",
       "1            2           2        253022876       1030   \n",
       "\n",
       "                  LoginID  ManagerID                         Title  BirthDate  \\\n",
       "0    adventure-works\\guy1       16.0  Production Technician - WC60 1972-05-15   \n",
       "1  adventure-works\\kevin0        6.0           Marketing Assistant 1977-06-03   \n",
       "\n",
       "  MaritalStatus Gender   HireDate  SalariedFlag  VacationHours  \\\n",
       "0             M      M 1996-07-31         False             21   \n",
       "1             S      M 1997-02-26         False             42   \n",
       "\n",
       "   SickLeaveHours  CurrentFlag ModifiedDate  \n",
       "0              30         True   2004-07-31  \n",
       "1              41         True   2004-07-31  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an EmployeeKey that ascends\n",
    "df_dim_employees.createOrReplaceTempView(\"employees\")\n",
    "sql_employees = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY EmployeeId) AS EmployeeKey\n",
    "    FROM employees;\n",
    "\"\"\"\n",
    "df_dim_employees = spark.sql(sql_employees)\n",
    "\n",
    "# Reorder columns and display the first two rows in a Pandas dataframe, dropping rowguid because it causes problems\n",
    "ordered_columns = ['EmployeeKey', 'EmployeeID', 'NationalIDNumber', 'ContactID', 'LoginID', 'ManagerID', 'Title', 'BirthDate','MaritalStatus','Gender','HireDate','SalariedFlag','VacationHours','SickLeaveHours','CurrentFlag','ModifiedDate']\n",
    "df_dim_employees = df_dim_employees[ordered_columns]\n",
    "df_dim_employees.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e69c3e1-6948-42f2-9b08-aa2c5b0e150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save to Data Lakehouse\n",
    "df_dim_employees.write.saveAsTable(f\"{dest_database}.dim_employees\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "74afabfc-c1c3-4463-bc42-a52643a137d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------+\n",
      "|            col_name|         data_type|comment|\n",
      "+--------------------+------------------+-------+\n",
      "|         EmployeeKey|               int|   NULL|\n",
      "|          EmployeeID|               int|   NULL|\n",
      "|    NationalIDNumber|       varchar(15)|   NULL|\n",
      "|           ContactID|               int|   NULL|\n",
      "|             LoginID|      varchar(256)|   NULL|\n",
      "|           ManagerID|               int|   NULL|\n",
      "|               Title|       varchar(50)|   NULL|\n",
      "|           BirthDate|         timestamp|   NULL|\n",
      "|       MaritalStatus|        varchar(1)|   NULL|\n",
      "|              Gender|        varchar(1)|   NULL|\n",
      "|            HireDate|         timestamp|   NULL|\n",
      "|        SalariedFlag|           boolean|   NULL|\n",
      "|       VacationHours|               int|   NULL|\n",
      "|      SickLeaveHours|               int|   NULL|\n",
      "|         CurrentFlag|           boolean|   NULL|\n",
      "|        ModifiedDate|         timestamp|   NULL|\n",
      "|                    |                  |       |\n",
      "|# Detailed Table ...|                  |       |\n",
      "|             Catalog|     spark_catalog|       |\n",
      "|            Database|adventureworks_dlh|       |\n",
      "+--------------------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeKey</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>ContactID</th>\n",
       "      <th>LoginID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>Title</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>CurrentFlag</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14417807</td>\n",
       "      <td>1209</td>\n",
       "      <td>adventure-works\\guy1</td>\n",
       "      <td>16</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>1972-05-15</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-07-31</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>253022876</td>\n",
       "      <td>1030</td>\n",
       "      <td>adventure-works\\kevin0</td>\n",
       "      <td>6</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>1977-06-03</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-02-26</td>\n",
       "      <td>False</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeKey  EmployeeID NationalIDNumber  ContactID  \\\n",
       "0            1           1         14417807       1209   \n",
       "1            2           2        253022876       1030   \n",
       "\n",
       "                  LoginID  ManagerID                         Title  BirthDate  \\\n",
       "0    adventure-works\\guy1         16  Production Technician - WC60 1972-05-15   \n",
       "1  adventure-works\\kevin0          6           Marketing Assistant 1977-06-03   \n",
       "\n",
       "  MaritalStatus Gender   HireDate  SalariedFlag  VacationHours  \\\n",
       "0             M      M 1996-07-31         False             21   \n",
       "1             S      M 1997-02-26         False             42   \n",
       "\n",
       "   SickLeaveHours  CurrentFlag ModifiedDate  \n",
       "0              30         True   2004-07-31  \n",
       "1              41         True   2004-07-31  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test: Describe and Preview Table\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_employees;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_employees LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45981318-4480-4ba0-9a3e-a84b87214106",
   "metadata": {},
   "source": [
    "### Step 2.2: Extracting purchaseorderheader from the MongoDB version of adventureworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3c70f837-6568-4dcd-8385-ff3b9eff95f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Freight</th>\n",
       "      <th>ModifiedDate</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>ShipMethodID</th>\n",
       "      <th>Status</th>\n",
       "      <th>SubTotal</th>\n",
       "      <th>TaxAmt</th>\n",
       "      <th>TotalDue</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244</td>\n",
       "      <td>5.0260</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>2001-05-17T00:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>201.0400</td>\n",
       "      <td>16.0832</td>\n",
       "      <td>222.1492</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231</td>\n",
       "      <td>6.8025</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>2001-05-17T00:00:00.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>272.1015</td>\n",
       "      <td>21.7681</td>\n",
       "      <td>300.6721</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  Freight             ModifiedDate                OrderDate  \\\n",
       "0         244   5.0260  2001-05-26T00:00:00.000  2001-05-17T00:00:00.000   \n",
       "1         231   6.8025  2001-05-26T00:00:00.000  2001-05-17T00:00:00.000   \n",
       "\n",
       "   PurchaseOrderID  RevisionNumber                 ShipDate  ShipMethodID  \\\n",
       "0                1               0  2001-05-26T00:00:00.000             3   \n",
       "1                2               0  2001-05-26T00:00:00.000             5   \n",
       "\n",
       "   Status  SubTotal   TaxAmt  TotalDue  VendorID  \n",
       "0       4  201.0400  16.0832  222.1492        83  \n",
       "1       1  272.1015  21.7681  300.6721        32  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongodb_args[\"collection\"] = \"purchaseorderheader\"\n",
    "\n",
    "df_dim_poh = get_mongodb_dataframe(spark, **mongodb_args)\n",
    "df_dim_poh.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dc88de36-bb9b-48df-bafd-171951c226af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderHeaderKey</th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Freight</th>\n",
       "      <th>ModifiedDate</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>ShipMethodID</th>\n",
       "      <th>Status</th>\n",
       "      <th>SubTotal</th>\n",
       "      <th>TaxAmt</th>\n",
       "      <th>TotalDue</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>5.0260</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>2001-05-17T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>201.0400</td>\n",
       "      <td>16.0832</td>\n",
       "      <td>222.1492</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>6.8025</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>2001-05-17T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>272.1015</td>\n",
       "      <td>21.7681</td>\n",
       "      <td>300.6721</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderHeaderKey  PurchaseOrderID  EmployeeID  Freight  \\\n",
       "0                       1                1         244   5.0260   \n",
       "1                       2                2         231   6.8025   \n",
       "\n",
       "              ModifiedDate                OrderDate  RevisionNumber  \\\n",
       "0  2001-05-26T00:00:00.000  2001-05-17T00:00:00.000               0   \n",
       "1  2001-05-26T00:00:00.000  2001-05-17T00:00:00.000               0   \n",
       "\n",
       "                  ShipDate  ShipMethodID  Status  SubTotal   TaxAmt  TotalDue  \\\n",
       "0  2001-05-26T00:00:00.000             3       4  201.0400  16.0832  222.1492   \n",
       "1  2001-05-26T00:00:00.000             5       1  272.1015  21.7681  300.6721   \n",
       "\n",
       "   VendorID  \n",
       "0        83  \n",
       "1        32  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add ascending Key\n",
    "df_dim_poh.createOrReplaceTempView(\"poh\")\n",
    "sql_poh = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY PurchaseOrderID) AS PurchaseOrderHeaderKey\n",
    "    FROM poh;\n",
    "\"\"\"\n",
    "df_dim_poh = spark.sql(sql_poh)\n",
    "\n",
    "# Reorder Columns and display first two rows in Pandas dataframe\n",
    "ordered_columns = ['PurchaseOrderHeaderKey','PurchaseOrderID','EmployeeID','Freight',\n",
    "                   'ModifiedDate','OrderDate','RevisionNumber',\n",
    "                  'ShipDate','ShipMethodID','Status','SubTotal','TaxAmt','TotalDue','VendorID']\n",
    "df_dim_poh = df_dim_poh [ordered_columns]\n",
    "df_dim_poh.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "05ea0d69-e3da-4c55-a4f0-3e51820fa250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as the dim_poh table in the Data Lakehouse\n",
    "df_dim_poh.write.saveAsTable(f\"{dest_database}.dim_poh\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0202ba13-6485-4b89-bc9e-12bc9ab55f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|PurchaseOrderHead...|                 int|   NULL|\n",
      "|     PurchaseOrderID|                 int|   NULL|\n",
      "|          EmployeeID|                 int|   NULL|\n",
      "|             Freight|              double|   NULL|\n",
      "|        ModifiedDate|              string|   NULL|\n",
      "|           OrderDate|              string|   NULL|\n",
      "|      RevisionNumber|                 int|   NULL|\n",
      "|            ShipDate|              string|   NULL|\n",
      "|        ShipMethodID|                 int|   NULL|\n",
      "|              Status|                 int|   NULL|\n",
      "|            SubTotal|              double|   NULL|\n",
      "|              TaxAmt|              double|   NULL|\n",
      "|            TotalDue|              double|   NULL|\n",
      "|            VendorID|                 int|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|  adventureworks_dlh|       |\n",
      "|               Table|             dim_poh|       |\n",
      "|        Created Time|Sat May 10 00:00:...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderHeaderKey</th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Freight</th>\n",
       "      <th>ModifiedDate</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>ShipMethodID</th>\n",
       "      <th>Status</th>\n",
       "      <th>SubTotal</th>\n",
       "      <th>TaxAmt</th>\n",
       "      <th>TotalDue</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>5.0260</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>2001-05-17T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>201.0400</td>\n",
       "      <td>16.0832</td>\n",
       "      <td>222.1492</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>231</td>\n",
       "      <td>6.8025</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>2001-05-17T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-26T00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>272.1015</td>\n",
       "      <td>21.7681</td>\n",
       "      <td>300.6721</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderHeaderKey  PurchaseOrderID  EmployeeID  Freight  \\\n",
       "0                       1                1         244   5.0260   \n",
       "1                       2                2         231   6.8025   \n",
       "\n",
       "              ModifiedDate                OrderDate  RevisionNumber  \\\n",
       "0  2001-05-26T00:00:00.000  2001-05-17T00:00:00.000               0   \n",
       "1  2001-05-26T00:00:00.000  2001-05-17T00:00:00.000               0   \n",
       "\n",
       "                  ShipDate  ShipMethodID  Status  SubTotal   TaxAmt  TotalDue  \\\n",
       "0  2001-05-26T00:00:00.000             3       4  201.0400  16.0832  222.1492   \n",
       "1  2001-05-26T00:00:00.000             5       1  272.1015  21.7681  300.6721   \n",
       "\n",
       "   VendorID  \n",
       "0        83  \n",
       "1        32  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test: Describe and Preview Table\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_poh;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_poh LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954fe0a-f734-494b-b10a-02450d137433",
   "metadata": {},
   "source": [
    "### Step 2.3: Extracting products from our CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5dcfe08f-b935-4d81-8852-05219c1c208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>MakeFlag</th>\n",
       "      <th>FinishedGoodsFlag</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>...</th>\n",
       "      <th>ProductLine</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductSubcategoryID</th>\n",
       "      <th>ProductModelID</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>b'\\xb7\\x15Bi\\xf7\\x08\\rL\\xac\\xb1\\xd74\\xbaD\\xc0\\...</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>BA-8327</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>b'\\x00'</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>b' &lt;\\xaeX:OIG\\xa7\\xd4\\xd5h\\x80l\\xc57'</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  ProductID             Name ProductNumber MakeFlag FinishedGoodsFlag  \\\n",
       "0    0          1  Adjustable Race       AR-5381  b'\\x00'           b'\\x00'   \n",
       "1    1          2     Bearing Ball       BA-8327  b'\\x00'           b'\\x00'   \n",
       "\n",
       "  Color  SafetyStockLevel  ReorderPoint  StandardCost  ...  ProductLine Class  \\\n",
       "0  None              1000           750           0.0  ...         None  None   \n",
       "1  None              1000           750           0.0  ...         None  None   \n",
       "\n",
       "  Style ProductSubcategoryID  ProductModelID  SellStartDate SellEndDate  \\\n",
       "0  None                  NaN             NaN     1998-06-01        None   \n",
       "1  None                  NaN             NaN     1998-06-01        None   \n",
       "\n",
       "  DiscontinuedDate                                            rowguid  \\\n",
       "0             None  b'\\xb7\\x15Bi\\xf7\\x08\\rL\\xac\\xb1\\xd74\\xbaD\\xc0\\...   \n",
       "1             None              b' <\\xaeX:OIG\\xa7\\xd4\\xd5h\\x80l\\xc57'   \n",
       "\n",
       "          ModifiedDate  \n",
       "0  2004-03-11 10:01:36  \n",
       "1  2004-03-11 10:01:36  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_file = (os.path.join(batch_dir, 'products.csv'))\n",
    "df_dim_products = spark.read.format('csv').options(header='true', inferSchema='true').load(dest_file)\n",
    "df_dim_products.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d41fa880-dc79-40b1-8eeb-84fcd92d2df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>DaysToManufacture</th>\n",
       "      <th>Class</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>BA-8327</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey  ProductID             Name ProductNumber Color  \\\n",
       "0           1          1  Adjustable Race       AR-5381  None   \n",
       "1           2          2     Bearing Ball       BA-8327  None   \n",
       "\n",
       "   SafetyStockLevel  ReorderPoint  StandardCost  ListPrice  DaysToManufacture  \\\n",
       "0              1000           750           0.0        0.0                  0   \n",
       "1              1000           750           0.0        0.0                  0   \n",
       "\n",
       "  Class SellStartDate SellEndDate         ModifiedDate  \n",
       "0  None    1998-06-01        None  2004-03-11 10:01:36  \n",
       "1  None    1998-06-01        None  2004-03-11 10:01:36  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Primary Key\n",
    "df_dim_products.createOrReplaceTempView(\"products\")\n",
    "sql_products = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (ORDER BY ProductID) AS ProductKey\n",
    "    FROM products;\n",
    "\"\"\"\n",
    "df_dim_products = spark.sql(sql_products)\n",
    "\n",
    "# Reorder columns and display the first two rows in a Pandas dataframe, dropping NAN and attachment columns\n",
    "ordered_columns = ['ProductKey', 'ProductID', 'Name', 'ProductNumber','Color',\n",
    "                   'SafetyStockLevel', 'ReorderPoint', 'StandardCost','ListPrice', \n",
    "                   'DaysToManufacture', 'Class','SellStartDate','SellEndDate',\n",
    "                   'ModifiedDate']\n",
    "df_dim_products = df_dim_products[ordered_columns]\n",
    "df_dim_products.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9990def-6199-4dae-9c4b-8a236372352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as the dim_products table in the Data Lakehouse\n",
    "df_dim_products.write.saveAsTable(f\"{dest_database}.dim_products\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef93e3c7-a20b-4604-b1ca-990b35943aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|          ProductKey|                 int|   NULL|\n",
      "|           ProductID|                 int|   NULL|\n",
      "|                Name|              string|   NULL|\n",
      "|       ProductNumber|              string|   NULL|\n",
      "|               Color|              string|   NULL|\n",
      "|    SafetyStockLevel|                 int|   NULL|\n",
      "|        ReorderPoint|                 int|   NULL|\n",
      "|        StandardCost|              double|   NULL|\n",
      "|           ListPrice|              double|   NULL|\n",
      "|   DaysToManufacture|                 int|   NULL|\n",
      "|               Class|              string|   NULL|\n",
      "|       SellStartDate|                date|   NULL|\n",
      "|         SellEndDate|                date|   NULL|\n",
      "|        ModifiedDate|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|             Catalog|       spark_catalog|       |\n",
      "|            Database|  adventureworks_dlh|       |\n",
      "|               Table|        dim_products|       |\n",
      "|        Created Time|Sat May 10 00:00:...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>DaysToManufacture</th>\n",
       "      <th>Class</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>BA-8327</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductKey  ProductID             Name ProductNumber Color  \\\n",
       "0           1          1  Adjustable Race       AR-5381  None   \n",
       "1           2          2     Bearing Ball       BA-8327  None   \n",
       "\n",
       "   SafetyStockLevel  ReorderPoint  StandardCost  ListPrice  DaysToManufacture  \\\n",
       "0              1000           750           0.0        0.0                  0   \n",
       "1              1000           750           0.0        0.0                  0   \n",
       "\n",
       "  Class SellStartDate SellEndDate         ModifiedDate  \n",
       "0  None    1998-06-01        None  2004-03-11 10:01:36  \n",
       "1  None    1998-06-01        None  2004-03-11 10:01:36  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test: Describe and Preview Table\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_products;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_products LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8452015-b9af-4bc0-b988-2272b2a786d4",
   "metadata": {},
   "source": [
    "### Step 2.4 Load in dim_date from the MySQL version of adventureworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9d553f1-9b5c-4369-af10-b44f35644287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sql_dim_date = f\"SELECT * FROM {mysql_args['db_name']}.dim_date\"\n",
    "df_dim_date = get_mysql_dataframe(spark, sql_dim_date, **mysql_args)\n",
    "df_dim_date.write.saveAsTable(f\"{dest_database}.dim_date\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "edb9f3c3-2cd8-4e99-a327-e15d046bd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as the dim_date table in the Data Lakehouse\n",
    "df_dim_date.write.saveAsTable(f\"{dest_database}.dim_date\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "38664c7c-d32e-4d56-8a6e-dd1fe81b86bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|            date_key|      int|   NULL|\n",
      "|           full_date|     date|   NULL|\n",
      "|           date_name| char(11)|   NULL|\n",
      "|        date_name_us| char(11)|   NULL|\n",
      "|        date_name_eu| char(11)|   NULL|\n",
      "|         day_of_week|  tinyint|   NULL|\n",
      "|    day_name_of_week| char(10)|   NULL|\n",
      "|        day_of_month|  tinyint|   NULL|\n",
      "|         day_of_year|      int|   NULL|\n",
      "|     weekday_weekend| char(10)|   NULL|\n",
      "|        week_of_year|  tinyint|   NULL|\n",
      "|          month_name| char(10)|   NULL|\n",
      "|       month_of_year|  tinyint|   NULL|\n",
      "|is_last_day_of_month|  char(1)|   NULL|\n",
      "|    calendar_quarter|  tinyint|   NULL|\n",
      "|       calendar_year|      int|   NULL|\n",
      "| calendar_year_month| char(10)|   NULL|\n",
      "|   calendar_year_qtr| char(10)|   NULL|\n",
      "|fiscal_month_of_year|  tinyint|   NULL|\n",
      "|      fiscal_quarter|  tinyint|   NULL|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_key</th>\n",
       "      <th>full_date</th>\n",
       "      <th>date_name</th>\n",
       "      <th>date_name_us</th>\n",
       "      <th>date_name_eu</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_name_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday_weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>is_last_day_of_month</th>\n",
       "      <th>calendar_quarter</th>\n",
       "      <th>calendar_year</th>\n",
       "      <th>calendar_year_month</th>\n",
       "      <th>calendar_year_qtr</th>\n",
       "      <th>fiscal_month_of_year</th>\n",
       "      <th>fiscal_quarter</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>fiscal_year_month</th>\n",
       "      <th>fiscal_year_qtr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000101</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000/01/01</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000102</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>2000/01/02</td>\n",
       "      <td>01/02/2000</td>\n",
       "      <td>02/01/2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_key   full_date    date_name date_name_us date_name_eu  day_of_week  \\\n",
       "0  20000101  2000-01-01  2000/01/01   01/01/2000   01/01/2000             7   \n",
       "1  20000102  2000-01-02  2000/01/02   01/02/2000   02/01/2000             1   \n",
       "\n",
       "  day_name_of_week  day_of_month  day_of_year weekday_weekend  ...  \\\n",
       "0       Saturday               1            1      Weekend     ...   \n",
       "1       Sunday                 2            2      Weekend     ...   \n",
       "\n",
       "   is_last_day_of_month calendar_quarter  calendar_year calendar_year_month  \\\n",
       "0                     N                1           2000          2000-01      \n",
       "1                     N                1           2000          2000-01      \n",
       "\n",
       "   calendar_year_qtr  fiscal_month_of_year fiscal_quarter fiscal_year  \\\n",
       "0         2000Q1                         7              3        2000   \n",
       "1         2000Q1                         7              3        2000   \n",
       "\n",
       "   fiscal_year_month  fiscal_year_qtr  \n",
       "0         2000-07          2000Q3      \n",
       "1         2000-07          2000Q3      \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Test: Describe and Preview Table\n",
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_date;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_date LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7ae35-5d00-4fef-a380-fe028c54cee9",
   "metadata": {},
   "source": [
    "### Step 2.5: Join dim_employees and dim_poh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8771f65c-96f8-42d6-adf3-c90de28c613a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>PurchaseOrderHeaderKey</th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>Freight</th>\n",
       "      <th>ModifiedDate</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>RevisionNumber</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>ShipMethodID</th>\n",
       "      <th>Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Title</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>CurrentFlag</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>509.9325</td>\n",
       "      <td>2001-06-09T00:00:00.000</td>\n",
       "      <td>2001-05-31T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-06-09T00:00:00.000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Buyer</td>\n",
       "      <td>1974-09-18</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-03-14</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5641</td>\n",
       "      <td>2002-01-23T00:00:00.000</td>\n",
       "      <td>2002-01-14T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>2002-01-23T00:00:00.000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Buyer</td>\n",
       "      <td>1974-09-18</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>1999-03-14</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>2004-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID  PurchaseOrderHeaderKey  PurchaseOrderID   Freight  \\\n",
       "0         164                       5                5  509.9325   \n",
       "1         164                      15               15    2.5641   \n",
       "\n",
       "              ModifiedDate                OrderDate  RevisionNumber  \\\n",
       "0  2001-06-09T00:00:00.000  2001-05-31T00:00:00.000               0   \n",
       "1  2002-01-23T00:00:00.000  2002-01-14T00:00:00.000               0   \n",
       "\n",
       "                  ShipDate  ShipMethodID  Status  ...  Title  BirthDate  \\\n",
       "0  2001-06-09T00:00:00.000             4       4  ...  Buyer 1974-09-18   \n",
       "1  2002-01-23T00:00:00.000             5       4  ...  Buyer 1974-09-18   \n",
       "\n",
       "   MaritalStatus  Gender   HireDate SalariedFlag  VacationHours  \\\n",
       "0              S       M 1999-03-14        False             59   \n",
       "1              S       M 1999-03-14        False             59   \n",
       "\n",
       "  SickLeaveHours  CurrentFlag ModifiedDate  \n",
       "0             49         True   2004-07-31  \n",
       "1             49         True   2004-07-31  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join PurchaseOrderHeader with Employees on EmployeeID\n",
    "df_dim_poh_new = df_dim_poh.join(\n",
    "    df_dim_employees,\n",
    "    on=\"EmployeeID\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "df_dim_poh_new.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "007f2c22-61b8-4498-8841-c11cd1a9f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmployeeID: integer (nullable = true)\n",
      " |-- PurchaseOrderHeaderKey: integer (nullable = false)\n",
      " |-- PurchaseOrderID: integer (nullable = true)\n",
      " |-- Freight: double (nullable = true)\n",
      " |-- ModifiedDate: string (nullable = true)\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- RevisionNumber: integer (nullable = true)\n",
      " |-- ShipDate: string (nullable = true)\n",
      " |-- ShipMethodID: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- SubTotal: double (nullable = true)\n",
      " |-- TaxAmt: double (nullable = true)\n",
      " |-- TotalDue: double (nullable = true)\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- EmployeeKey: integer (nullable = false)\n",
      " |-- NationalIDNumber: string (nullable = true)\n",
      " |-- ContactID: integer (nullable = true)\n",
      " |-- LoginID: string (nullable = true)\n",
      " |-- ManagerID: integer (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- BirthDate: timestamp (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- HireDate: timestamp (nullable = true)\n",
      " |-- SalariedFlag: boolean (nullable = true)\n",
      " |-- VacationHours: integer (nullable = true)\n",
      " |-- SickLeaveHours: integer (nullable = true)\n",
      " |-- CurrentFlag: boolean (nullable = true)\n",
      " |-- ModifiedDate: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dim_poh_new.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f8866-347d-443e-80fb-168133fc078c",
   "metadata": {},
   "source": [
    "## Step 3: Integrating Cold Path Batch Data with Streaming Data (Hot Path)\n",
    "### Step 3.1 Verify the location of source files on the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a90865b1-a69c-4cf7-9efd-ac4effe5f17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purchaseorderdetail_part1.json</td>\n",
       "      <td>6064400</td>\n",
       "      <td>2025-05-10 03:59:37.888707638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purchaseorderdetail_part2.json</td>\n",
       "      <td>6071713</td>\n",
       "      <td>2025-05-10 03:59:41.548504353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purchaseorderdetail_part3.json</td>\n",
       "      <td>6073583</td>\n",
       "      <td>2025-05-10 03:59:43.252766131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name     size             modification_time\n",
       "0  purchaseorderdetail_part1.json  6064400 2025-05-10 03:59:37.888707638\n",
       "1  purchaseorderdetail_part2.json  6071713 2025-05-10 03:59:41.548504353\n",
       "2  purchaseorderdetail_part3.json  6073583 2025-05-10 03:59:43.252766131"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(stream_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc419d-07b5-4476-9f29-c24e5f0bf123",
   "metadata": {},
   "source": [
    "### Step 3.2 Bronze Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d42087-0dc1-4552-9335-4e05a4f6bf76",
   "metadata": {},
   "source": [
    "#### Step 3.2.1 Read \"Raw\" JSON file data into a Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8c15e0cc-fc16-43c3-a4e3-f2023089e6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bronze = (\n",
    "    spark.readStream \\\n",
    "    .option(\"schemaLocation\", output_bronze) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .json(stream_dir)\n",
    ")\n",
    "\n",
    "df_bronze.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5d166-3e9d-4842-8299-62298828cc0e",
   "metadata": {},
   "source": [
    "#### Step 3.2.2 Write the streaming data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f9e5d664-ad8e-4062-bfb0-3e11895ff522",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_bronze = os.path.join(output_bronze, '_checkpoint')\n",
    "\n",
    "bronze_query = (\n",
    "    df_bronze\n",
    "    # Add Current Timestamp and Input Filename columns for Traceability\n",
    "    .withColumn(\"receipt_time\", current_timestamp())\n",
    "    .withColumn(\"source_file\", input_file_name())\n",
    "    \n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"bronze\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", checkpoint_bronze) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(output_bronze)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2824dca5-7697-4167-9370-8a388877591f",
   "metadata": {},
   "source": [
    "#### Step 3.2.3 Unit Test: Implement Query Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d8943b63-99c4-4e94-8649-a75394659b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: d96dc4f8-9113-4838-8d52-fe4f75753e46\n",
      "Query Name: bronze\n",
      "Query Status: {'message': 'Initializing sources', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {bronze_query.id}\")\n",
    "print(f\"Query Name: {bronze_query.name}\")\n",
    "print(f\"Query Status: {bronze_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "be1b3369-251e-46c4-9fe1-edc4d21bce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb773116-3594-4f7e-8d0f-4a1b35e51c30",
   "metadata": {},
   "source": [
    "### Step 3.3. Create the Silver Layer: Integrate \"Cold-path\" Data & Make Transformations\n",
    "#### Step 3.3.1 Prepare Role-Playing Dimension Primary and Business Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "178775b8-ec4c-4beb-b16e-4b250dd8d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_due_date = df_dim_date.select(col(\"date_key\").alias(\"DueDateKey\"), col(\"full_date\").alias(\"DueFullDate\"))\n",
    "df_dim_modified_date = df_dim_date.select(col(\"date_key\").alias(\"ModifiedDateKey\"), col(\"full_date\").alias(\"ModifiedFullDate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf68a5-cd3e-4e1c-8546-80eb3b4caaf8",
   "metadata": {},
   "source": [
    "#### Step 3.3.2 Define Silver Query to Join Streaming with Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "837dbfe6-3fe3-4083-9292-8dbc7ce42ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver = spark.readStream.format(\"parquet\").load(output_bronze) \\\n",
    "    .join(df_dim_poh_new, \"PurchaseOrderID\") \\\n",
    "    .join(df_dim_products, \"ProductID\") \\\n",
    "    .join(df_dim_due_date, df_dim_due_date.DueFullDate.cast(DateType()) == col(\"DueDate\").cast(DateType()), \"left_outer\") \\\n",
    "    .join(df_dim_modified_date, df_dim_modified_date.ModifiedFullDate.cast(DateType()) == col(\"ModifiedFullDate\").cast(DateType()), \"left_outer\") \\\n",
    "    .select(col(\"PurchaseOrderID\").cast(LongType()), \\\n",
    "            col(\"PurchaseOrderDetailID\").cast(LongType()), \\\n",
    "            df_dim_poh_new.EmployeeKey.cast(LongType()), \\\n",
    "            df_dim_poh_new.PurchaseOrderHeaderKey.cast(LongType()), \\\n",
    "            df_dim_products.ProductKey.cast(LongType()), \\\n",
    "            df_dim_due_date.DueDateKey.cast(LongType()), \\\n",
    "            df_dim_modified_date.ModifiedDateKey.cast(LongType()), \\\n",
    "            col(\"OrderQty\"), \\\n",
    "            col(\"UnitPrice\"), \\\n",
    "            col(\"LineTotal\"), \\\n",
    "            col(\"ReceivedQty\"), \\\n",
    "            col(\"RejectedQty\"), \\\n",
    "            col(\"StockedQty\"), \\\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "23add45c-c766-4833-9112-5b7fddf6a86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_silver.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fb36393f-e732-442e-ab67-e4e499a0d4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PurchaseOrderID: long (nullable = true)\n",
      " |-- PurchaseOrderDetailID: long (nullable = true)\n",
      " |-- EmployeeKey: long (nullable = false)\n",
      " |-- PurchaseOrderHeaderKey: long (nullable = false)\n",
      " |-- ProductKey: long (nullable = false)\n",
      " |-- DueDateKey: long (nullable = true)\n",
      " |-- ModifiedDateKey: long (nullable = true)\n",
      " |-- OrderQty: long (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- LineTotal: double (nullable = true)\n",
      " |-- ReceivedQty: double (nullable = true)\n",
      " |-- RejectedQty: double (nullable = true)\n",
      " |-- StockedQty: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f258c9f1-a406-4a93-ac41-aadd43ca62fc",
   "metadata": {},
   "source": [
    "#### Step 3.3.3. Write the Transformed Streaming data to the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e254d244-82a4-4e52-aebe-16d4ab25d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_silver = os.path.join(output_silver, '_checkpoint')\n",
    "\n",
    "silver_query = (\n",
    "    df_silver.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"silver\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", checkpoint_silver) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(output_silver)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2806081a-3983-4451-93a5-362751fc457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 852b14fe-ec1c-4770-929c-d91e93cebf03\n",
      "Query Name: silver\n",
      "Query Status: {'message': 'Initializing sources', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query ID: {silver_query.id}\")\n",
    "print(f\"Query Name: {silver_query.name}\")\n",
    "print(f\"Query Status: {silver_query.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da71abf-afd0-4f3d-99bb-fd2485652e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f888e32-891f-4e70-8fb9-e50692c182d8",
   "metadata": {},
   "source": [
    "### Step 3.4. Create the Gold Layer: Perform Aggregations\n",
    "#### Step 3.4.1 Define a Query to Create a Business Report\n",
    "This query counts the number of ordes received per employee per month by:\n",
    "Joining with the df_dim_date table on DueDateKey;\n",
    "Grouping by EmployeeKey, month_of_year, and optionally month_name;\n",
    "Counting the number of received orders (use PurchaseOrderID as a proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013fbc7-9e58-4ecb-9816-f90aa2d242e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_avg_order_qty = spark.readStream.format(\"parquet\").load(output_silver) \\\n",
    "    .join(df_dim_products, \"ProductKey\") \\\n",
    "    .join(df_dim_employees, \"EmployeeKey\") \\\n",
    "    .groupBy(\"EmployeeID\", \"ProductID\") \\\n",
    "    .agg(avg(\"OrderQty\").alias(\"Average Order Quantity\")) \\\n",
    "    .orderBy(\"EmployeeID\", \"ProductID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4514908-67af-48ec-9446-3cb7aff02a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_order_qty.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac922737-666f-404e-9a6d-1e5373e4dd9e",
   "metadata": {},
   "source": [
    "#### 3.4.2. Write the Streaming data to a Parquet File in \"Complete\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a89cf-51d4-4409-b49d-d38dda3a9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_query = (\n",
    "    df_avg_order_qty.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"purchase_orders_by_average_order_quantity\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1aa773-277f-4dd6-b630-07de9b9c542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_until_stream_is_ready(gold_query, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8627b-aec6-4984-bcac-c74c08169221",
   "metadata": {},
   "source": [
    "#### 3.4.3. Query the Gold Data from Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29f6a4-ed76-45ee-aa33-0b06a149114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_orders_by_average_order_quantity = spark.sql(\"SELECT * FROM purchase_orders_by_average_order_quantity\")\n",
    "df_purchase_orders_by_average_order_quantity.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785746bd-f229-4f32-ae4d-b2943db9415a",
   "metadata": {},
   "source": [
    "#### 3.4.4 Create the Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d522a-059e-4006-96ce-1b67ea87c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_orders_by_average_order_qty_gold_final = df_purchase_orders_by_average_order_quantity \\\n",
    "    .select(\n",
    "        col(\"EmployeeID\"),\n",
    "        col(\"ProductID\"),\n",
    "        col(\"Average Order Quantity\")\n",
    "    ) \\\n",
    "    .orderBy(asc(\"Average Order Quantity\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d559922-7d35-47a0-a76b-cc0c96cd13d3",
   "metadata": {},
   "source": [
    "#### 3.4.5. Load the Final Results into a New Table and Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67771b78-98e7-47a7-9d69-af10a5b21307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_orders_by_average_order_qty_gold_final.write.saveAsTable(f\"{dest_database}.orders_by_avg_order_qty\", mode=\"overwrite\")\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.orders_by_avg_order_qty\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64496756-c559-48a3-a93e-1f3d349feb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
